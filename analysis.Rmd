---
title: 'STAT 447C: Final Project'
author: "Andrew Tran"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
library(tidyverse)
library(loo)
library(reshape2)
library(ggplot2)
library(pROC)
library(broom)
library(regclass)
library(rstan)
library(bayesplot)
```

## Introduction

## Goals of the project

### Methodology

## Data description

```{r}
df <- read.csv("data/breast_cancer_wisconsin.csv")
df <- as_tibble(df)
```

Our response variable is `Diagnosis`, which is categorical. Currently, it's being labelled as **M** (malignant) or **B** (benign). We want to transform it into binary values so that **1** and **0** are equivalent to **M** and **B** respectively.

```{r}
df$Diagnosis <- factor(df$Diagnosis)
df$Diagnosis <- as.numeric(df$Diagnosis) - 1
```

The Breast Cancer Wisconsin (Diagnostic) data set has 30 explanatory variables. However, in fact, they have 10 main features. For each feature, the mean, standard error, and worst/largest  values are recorded. For example, for a single observation in the data, `radius1` is the mean of distances from center to points on the perimeter, `radius2` is the standard error those distances, and `radius3` is largest distance measured. For the sake of length, we are only interested the means.

```{r}
df <- df[, 1:11]
```

These ten real-valued features are measurements taken and computed for each cell nucleus:

\begin{center}
  \begin{tabular}{|c c c|} 
    \hline
    Variable & Type & Description \\
    \hline\hline
    Radius & Quantitative & Distance from center to points on the perimeter of the tumor \\ 
    \hline
    Texture & Quantitative & Gray-scale value \\
    \hline
    Perimeter & Quantitative & Size of the tumor\\
    \hline
    Area & Quantitative & Area of the tumor \\
    \hline
    Smoothness & Quantitative & Local variation in radius length \\
    \hline
    Compactness & Quantitative & $\frac{\text{perimeter}^2}{\text{area}} - 1$ \\
    \hline
    Concavity & Quantitative & Severity of concave portions of the contour\\
    \hline
    Concave points & Quantitative & Number of concave portions of the contour\\
    \hline
    Symmetry & Quantitative & Symmetrical measurement of the tumor\\
    \hline
    Fractal dimension & Quantitative & $\text{coastline approximation} - 1$\\
    \hline
  \end{tabular}
\end{center}

## Base model

### Frequentist

Fitting a base model with every explanatory variables included is a straightforward process with the Frequentist approach.

```{r}
frequentist.base_reg <- 
  glm(Diagnosis ~ ., data = df, family = binomial(link = "logit"))
```

### Bayesian

In contrast to the simplicity of the Frequentist approach, fitting a Bayesian regression model is a more hands-on process.

Let $\beta_0$ be the intercept parameter and $\beta_1,...\beta_{10}$ be the slope parameters for `radius`, `texture`, `perimeter`, `area`, `smoothness`, `compactness`, `concavity`, `concave_points`, `symmetry`, and `fractal_dimension` correspondingly.

To fit a Bayesian logistic regression to our data, we need to specify our Bayesian model. One of the important tasks when specifying our model is the selection of prior distributions. We often select generic weakly informative priors like $Normal(0,1)$ to perform regression task in Bayesian approach. This choice could work in our case as we are attempting to fit a logistic regression model. However, logistic regression can also become unstable from separation, a problem when the outcome variable separates a predictor variable perfectly. (Bayesian Data Analysis, p. 412) To avoid this problem, Gelman et al. (2008) suggested the Cauchy distribution with center 0 and scale set to 2.5 for the slopes and 10 for the intercept. We will employ this choice of prior to model Bayesian logistic regression. To proceed with approach, it is required that we center and scale our nonbinary variables to have mean 0 and standard deviation 0.5. (Gelman et al., 2008)

```{r, echo=FALSE}
bayesian.df <- df
bayesian.df$radius1 <- df$radius1 - mean(df$radius1)
bayesian.df$radius1 <- df$radius1/sd(df$radius1)/2

bayesian.df$texture1 <- df$texture1 - mean(df$texture1)
bayesian.df$texture1 <- df$texture1/sd(df$texture1)/2

bayesian.df$perimeter1 <- df$perimeter1 - mean(df$perimeter1)
bayesian.df$perimeter1 <- df$perimeter1/sd(df$perimeter1)/2

bayesian.df$area1 <- df$area1 - mean(df$area1)
bayesian.df$area1 <- df$area1/sd(df$area1)/2

bayesian.df$smoothness1 <- df$smoothness1 - mean(df$smoothness1)
bayesian.df$smoothness1 <- df$smoothness1/sd(df$smoothness1)/2

bayesian.df$compactness1 <- df$compactness1 - mean(df$compactness1)
bayesian.df$compactness1 <- df$compactness1/sd(df$compactness1)/2

bayesian.df$concavity1 <- df$concave_points1 - mean(df$concavity1)
bayesian.df$concavity1 <- df$concavity1/sd(df$concavity1)/2

bayesian.df$concave_points1 <- df$concave_points1 - mean(df$concave_points1)
bayesian.df$concave_points1 <- df$concave_points1/sd(df$concave_points1)/2

bayesian.df$symmetry1 <- df$symmetry1 - mean(df$symmetry1)
bayesian.df$symmetry1 <- df$symmetry1/sd(df$symmetry1)/2

bayesian.df$fractal_dimension1 <- df$fractal_dimension1 - mean(df$fractal_dimension1)
bayesian.df$fractal_dimension1 <- df$fractal_dimension1/sd(df$fractal_dimension1)/2
```

\begin{align}
  \beta_0 & \sim \text{Cauchy}(0, 10) \\
  \beta_i & \overset{\text{iid}}{\sim} \text{Cauchy}(0, 2.5) & \text{ for } i \in \{1,...,10\} \\
  y_n|\beta & \sim \text{Bern}(\text{logistic}(\beta_0 + \beta_1x_{n,1} + ... + \beta_{10}x_{n,10})) & n \in \{1,...,n_\text{obs}\}
\end{align}

```{r, echo=FALSE}
N_obs <- nrow(bayesian.df)
N_train <- N_obs-1 
bayesian.base_reg.dat <- list(
  N = N_train,
  x1 = bayesian.df$radius1[-N_obs],
  x2 = bayesian.df$texture1[-N_obs],
  x3 = bayesian.df$perimeter1[-N_obs],
  x4 = bayesian.df$area1[-N_obs],
  x5 = bayesian.df$smoothness1[-N_obs],
  x6 = bayesian.df$compactness1[-N_obs],
  x7 = bayesian.df$concavity1[-N_obs],
  x8 = bayesian.df$concave_points1[-N_obs],
  x9 = bayesian.df$symmetry1[-N_obs],
  x10 = bayesian.df$fractal_dimension1[-N_obs],
  y = bayesian.df$Diagnosis[-N_obs],
  
  x1_pred = bayesian.df$radius1[N_obs],
  x2_pred = bayesian.df$texture1[N_obs],
  x3_pred = bayesian.df$perimeter1[N_obs],
  x4_pred = bayesian.df$area1[N_obs],
  x5_pred = bayesian.df$smoothness1[N_obs],
  x6_pred = bayesian.df$compactness1[N_obs],
  x7_pred = bayesian.df$concavity1[N_obs],
  x8_pred = bayesian.df$concave_points1[N_obs],
  x9_pred = bayesian.df$symmetry1[N_obs],
  x10_pred = bayesian.df$fractal_dimension1[N_obs]
)
```

```{r, results='hide'}
bayesian.base_model <- stan_model("base_logistic.stan")
bayesian.base_reg <- sampling(
  bayesian.base_model,
  data = bayesian.base_reg.dat,
  seed = 123, iter = 1000
)
```

## Model with the exclusion of high correlated explanatory variables

```{r, echo=FALSE}
cor_mat <- round(cor(df[, 2:11]), 2)
melted_cor_mat <- melt(cor_mat)
ggplot(data = melted_cor_mat, aes(x=Var1, y=Var2, fill=value)) +
  geom_tile() +
  geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  xlab("") + ylab("") + ggtitle("Correlation Matrix")
```

Highly correlated variables:

- `radius` and `perimeter`: 1
- `radius` and `area`: 0.99
- `radius` and `concave_points`: 0.82
- `perimeter` and `area`: 0.99
- `perimeter` and `concavity`: 0.85
- `perimeter` and `concave_points`: 0.71
- `area` and `concave_points`: 0.82
- `compactness` and `concavity`: 0.89
- `compactness` and `concave_points`: 0.84
- `concavity` and `concave_points`: 0.92

The possible loss of precision when including unimportant predictors is usually viewed as a relatively small price to pay for the general validity of predictions and inferences about estimands of interest. (Bayesian Data Analysis, p. 367)

### Frequentist

```{r}
frequentist.better_reg <- 
  glm(Diagnosis ~ radius1 + texture1 + smoothness1 + concavity1 + symmetry1 + fractal_dimension1, data = df, family = binomial(link = "logit"))
```

### Bayesian

why colllinearity is bad in Bayesian
The near-collinearity of the data means that the posterior variance of the regression coefficients would be high in this hypothetical case. Another problem in addition to increased uncertainty conditional on the regression model is that in practice the inferences would be highly sensitive to the modelâ€™s assumption that $E(y|x, \theta)$ is linear in x. (Bayesian Data Analysis, p. 366)

\begin{align}
  \beta_0 & \sim \text{Cauchy}(0, 10) \\
  \beta_1 & \sim \text{Cauchy}(0, 2.5) \\
  \beta_2 & \sim \text{Cauchy}(0, 2.5) \\
  \beta_5 & \sim \text{Cauchy}(0, 2.5) \\
  \beta_7 & \sim \text{Cauchy}(0, 2.5) \\
  \beta_9 & \sim \text{Cauchy}(0, 2.5) \\
  \beta_10 & \sim \text{Cauchy}(0, 2.5) \\
  y_n|\beta & \sim \text{Bern}(\text{logistic}(\beta_0 + \beta_1x_{n,1} + \beta_2x_{n,2} + \beta_5x_{n,5} + \beta_7x_{n,7} + \beta_9x_{n,9} + \beta_{10}x_{n,10})) & n \in \{1,...,n_\text{obs}\}
\end{align}

```{r, echo=FALSE}
N_obs <- nrow(bayesian.df)
N_train <- N_obs-1 
bayesian.better_reg.dat <- list(
  N = N_train,
  x1 = bayesian.df$radius1[-N_obs],
  x2 = bayesian.df$texture1[-N_obs],
  x5 = bayesian.df$smoothness1[-N_obs],
  x7 = bayesian.df$concavity1[-N_obs],
  x9 = bayesian.df$symmetry1[-N_obs],
  x10 = bayesian.df$fractal_dimension1[-N_obs],
  y = bayesian.df$Diagnosis[-N_obs],
  
  x1_pred = bayesian.df$radius1[N_obs],
  x2_pred = bayesian.df$texture1[N_obs],
  x5_pred = bayesian.df$smoothness1[N_obs],
  x7_pred = bayesian.df$concavity1[N_obs],
  x9_pred = bayesian.df$symmetry1[N_obs],
  x10_pred = bayesian.df$fractal_dimension1[N_obs]
)
```

```{r, results='hide'}
bayesian.better_model <- stan_model("better_logistic.stan")
bayesian.better_reg <- sampling(
  bayesian.better_model,
  data = bayesian.better_reg.dat,
  seed = 123, iter = 1000
)
```

## Model comparison

### Frequentist

```{r}
AIC(frequentist.base_reg)
```

```{r}
AIC(frequentist.better_reg)
```

### Bayesian

#### WAIC

\

```{r}
waic(extract_log_lik(bayesian.base_reg))$waic
```

```{r}
waic(extract_log_lik(bayesian.better_reg))$waic
```

#### LOOIC

\

```{r}
loo(extract_log_lik(bayesian.base_reg))$looic
```

```{r}
loo(extract_log_lik(bayesian.better_reg))$looic
```

## Model diagnostics

### Frequentist

Lineairty assumption

Influential outliers

```{r}
model.data <- augment(frequentist.better_reg) %>% mutate(index = 1:n()) 
model.data %>% filter(abs(.std.resid) > 3)
```

Multicollinearity/VIF

```{r}
VIF(frequentist.better_reg)
```

### Bayesian

#### Prior predictive checks

\

```{r, include=FALSE}
suppressPackageStartupMessages(library(extraDistr))
```


```{r}
logistic_regression <- function(X) {
  b <- append(rcauchy(1, 0, 10), rcauchy(ncol(X) - 1, 0, 2.5))
  p <- plogis(as.vector(X %*% b))
  y <- rbern(nrow(X), p)
  mean(y)
}
```

```{r}
pred_prob = 0.9
n_obs = 100
n_sim = 100000
opar = par(mfrow=c(1,3))
for(n_pred in c(2,4,15)) {
    X = matrix(rbern(n_obs*n_pred, pred_prob), nrow=n_obs)
    simulated_ybars = replicate(n_sim, logistic_regression(X))
    hist(simulated_ybars, breaks=20, ylim=c(0,17000),
         main=paste(n_pred, "predictors"), xlab = "Average outcome")
}
```



#### MCMC diagnostics

\

```{r}
mcmc_trace(bayesian.better_reg, pars = c("b0")) + theme_minimal()
```

```{r}
mcmc_rank_hist(bayesian.better_reg, pars = c("b0")) + theme_minimal()
```

## Direct comparison between Frequentist and Bayesian

## Appendix

