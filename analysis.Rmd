---
title: 'STAT 447C: Final Project'
author: "Andrew Tran"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE)
library(tidyverse)
# library(LaplacesDemon)
library(loo)
library(reshape2)
library(ggplot2)
library(pROC)
library(broom)
library(regclass)
require(rstan)
```

## Introduction

## Goals of the project

### Methodology

## Data description

```{r}
df <- read.csv("data/breast_cancer_wisconsin.csv")
df <- as_tibble(df)
```

Our response variable is `Diagnosis`, which is categorical. Currently, it's being labelled as **M** (malignant) or **B** (benign). We want to transform it into binary values so that **1** and **0** are equivalent to **M** and **B** respectively.

```{r}
df$Diagnosis <- factor(df$Diagnosis)
df$Diagnosis <- as.numeric(df$Diagnosis) - 1
```

The Breast Cancer Wisconsin (Diagnostic) data set has 30 explanatory variables. However, in fact, they have 10 main features. For each feature, the mean, standard error, and worst/largest  values are recorded. For example, for a single observation in the data, `radius1` is the mean of distances from center to points on the perimeter, `radius2` is the standard error those distances, and `radius3` is largest distance measured. For the sake of length, we are only interested the means.

```{r}
df <- df[, 1:11]
```

These ten real-valued features are measurements taken and computed for each cell nucleus:

\begin{center}
  \begin{tabular}{|c c c|} 
    \hline
    Variable & Type & Description \\
    \hline\hline
    Radius & Quantitative & Distance from center to points on the perimeter of the tumor \\ 
    \hline
    Texture & Quantitative & Gray-scale value \\
    \hline
    Perimeter & Quantitative & Size of the tumor\\
    \hline
    Area & Quantitative & Area of the tumor \\
    \hline
    Smoothness & Quantitative & Local variation in radius length \\
    \hline
    Compactness & Quantitative & $\frac{\text{perimeter}^2}{\text{area}} - 1$ \\
    \hline
    Concavity & Quantitative & Severity of concave portions of the contour\\
    \hline
    Concave points & Quantitative & Number of concave portions of the contour\\
    \hline
    Symmetry & Quantitative & Symmetrical measurement of the tumor\\
    \hline
    Fractal dimension & Quantitative & $\text{coastline approximation} - 1$\\
    \hline
  \end{tabular}
\end{center}

We will also divide the dataset into a training dataset of 500 observations and a testing dataset of 69 observations.

```{r}
train_data <- df[1:500,]
test_data <- df[501:569,]
```

## Frequentist logistic regression

### Naive model with every explanatory variables included

```{r}
frequentist.naive_reg <- 
  glm(Diagnosis ~ ., data = train_data, family = binomial(link = "logit"))
```

### Model with the exlcusion of high correlated explanatory variables

```{r, echo=FALSE}
cor_mat <- round(cor(train_data[, 2:11]), 2)
melted_cor_mat <- melt(cor_mat)
ggplot(data = melted_cor_mat, aes(x=Var1, y=Var2, fill=value)) +
  geom_tile() +
  geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  xlab("") + ylab("") + ggtitle("Correlation Matrix")
```

Highly correlated variables:

- `radius` and `perimeter`: 1
- `radius` and `area`: 0.99
- `radius` and `concave_points`: 0.82
- `perimeter` and `area`: 0.99
- `perimeter` and `concavity`: 0.85
- `perimeter` and `concave_points`: 0.71
- `area` and `concave_points`: 0.82
- `compactness` and `concavity`: 0.89
- `compactness` and `concave_points`: 0.84
- `concavity` and `concave_points`: 0.92

The possible loss of precision when including unimportant predictors is usually viewed as a relatively small price to pay for the general validity of predictions and inferences about estimands of interest. (Bayesian Data Analysis, p. 367)

```{r}
frequentist.better_reg <- 
  glm(Diagnosis ~ radius1 + texture1 + smoothness1 + concavity1 + symmetry1 + fractal_dimension1, data = train_data, family = binomial(link = "logit"))
```


### Model comparison

AIC

```{r, echo=FALSE}
frequentist.naive_reg.pred <- predict(frequentist.naive_reg, newdata = test_data)
frequentist.naive_reg.roc_curve <- roc(response = test_data$Diagnosis, 
                                       predictor = frequentist.naive_reg.pred, quiet = TRUE)
plot(frequentist.naive_reg.roc_curve,
     print.auc=TRUE, col="blue", lwd=3, lty=2,
     main="ROC Curve of Frequentist naive model")
```

```{r, echo=FALSE}
frequentist.better_reg.pred <- predict(frequentist.better_reg, newdata = test_data)
frequentist.better_reg.roc_curve <- roc(response = test_data$Diagnosis, 
                                       predictor = frequentist.better_reg.pred, quiet = TRUE)
plot(frequentist.better_reg.roc_curve,
     print.auc=TRUE, col="blue", lwd=3, lty=2,
     main="ROC Curve of Frequentist better model")
```

### Model diagnostics

Influential

```{r}
model.data <- augment(frequentist.better_reg) %>% mutate(index = 1:n()) 
model.data %>% filter(abs(.std.resid) > 3)
```

Multicollinearity/VIF

```{r}
VIF(frequentist.better_reg)
```


## Bayesian logistic regression

Let $\beta_0$ be the intercept parameter and $\beta_1,...\beta_{10}$ be the slope parameters for `radius`, `texture`, `perimeter`, `area`, `smoothness`, `compactness`, `concavity`, `concave_points`, `symmetry`, and `fractal_dimension` correspondingly.

To fit a Bayesian logistic regression to our data, we need to specify our Bayesian model. One of the important tasks when specifying our model is the selection of prior distributions. We often select generic weakly informative priors like $Normal(0,1)$ to perform regression task in Bayesian approach. This choice could work in our case as we are attempting to fit a logistic regression model. However, logistic regression can also become unstable from separation, a problem when the outcome variable separates a predictor variable perfectly. (Bayesian Data Analysis, p. 412) To avoid this problem, Gelman et al. (2008) suggested the Cauchy distribution with center 0 and scale set to 2.5 for the slopes and 10 for the intercept. We will employ this choice of prior to model Bayesian logistic regression. To proceed with approach, it is required that we center and scale our nonbinary variables to have mean 0 and standard deviation 0.5. (Gelman et al., 2008)

```{r, echo=FALSE}
bayesian.df <- df
bayesian.df$radius1 <- df$radius1 - mean(df$radius1)
bayesian.df$radius1 <- df$radius1/sd(df$radius1)/2

bayesian.df$texture1 <- df$texture1 - mean(df$texture1)
bayesian.df$texture1 <- df$texture1/sd(df$texture1)/2

bayesian.df$perimeter1 <- df$perimeter1 - mean(df$perimeter1)
bayesian.df$perimeter1 <- df$perimeter1/sd(df$perimeter1)/2

bayesian.df$area1 <- df$area1 - mean(df$area1)
bayesian.df$area1 <- df$area1/sd(df$area1)/2

bayesian.df$smoothness1 <- df$smoothness1 - mean(df$smoothness1)
bayesian.df$smoothness1 <- df$smoothness1/sd(df$smoothness1)/2

bayesian.df$compactness1 <- df$compactness1 - mean(df$compactness1)
bayesian.df$compactness1 <- df$compactness1/sd(df$compactness1)/2

bayesian.df$concavity1 <- df$concave_points1 - mean(df$concavity1)
bayesian.df$concavity1 <- df$concavity1/sd(df$concavity1)/2

bayesian.df$concave_points1 <- df$concave_points1 - mean(df$concave_points1)
bayesian.df$concave_points1 <- df$concave_points1/sd(df$concave_points1)/2

bayesian.df$symmetry1 <- df$symmetry1 - mean(df$symmetry1)
bayesian.df$symmetry1 <- df$symmetry1/sd(df$symmetry1)/2

bayesian.df$fractal_dimension1 <- df$fractal_dimension1 - mean(df$fractal_dimension1)
bayesian.df$fractal_dimension1 <- df$fractal_dimension1/sd(df$fractal_dimension1)/2

bayesian.train_data <- df[1:500,]
bayesian.test_data <- df[501:569,]
```


### Model with priors for every explanatory variables

\begin{align}
  \beta_0 & \sim \text{Cauchy}(0, 10) \\
  \beta_i & \overset{\text{iid}}{\sim} \text{Cauchy}(0, 2.5) & \text{ for } i \in \{1,...,10\} \\
  y_n|\beta & \sim \text{Bern}(\text{logistic}(\beta_0 + \beta_1x_{n,1} + ... + \beta_{10}x_{n,10})) & n \in \{1,...,n_\text{obs}\}
\end{align}

```{r, echo=FALSE}
bayesian.base_reg.dat <- list(
  N = 500,
  x1 = bayesian.train_data$radius1,
  x2 = bayesian.train_data$texture1,
  x3 = bayesian.train_data$perimeter1,
  x4 = bayesian.train_data$area1,
  x5 = bayesian.train_data$smoothness1,
  x6 = bayesian.train_data$compactness1,
  x7 = bayesian.train_data$concavity1,
  x8 = bayesian.train_data$concave_points1,
  x9 = bayesian.train_data$symmetry1,
  x10 = bayesian.train_data$fractal_dimension1,
  y = bayesian.train_data$Diagnosis,
  N_new = 69,
  x1_new = bayesian.test_data$radius1,
  x2_new = bayesian.test_data$texture1,
  x3_new = bayesian.test_data$perimeter1,
  x4_new = bayesian.test_data$area1,
  x5_new = bayesian.test_data$smoothness1,
  x6_new = bayesian.test_data$compactness1,
  x7_new = bayesian.test_data$concavity1,
  x8_new = bayesian.test_data$concave_points1,
  x9_new = bayesian.test_data$symmetry1,
  x10_new = bayesian.test_data$fractal_dimension1
)
```


```{r, message=FALSE}
bayesian.base_reg <- stan(
  seed = 123,
  file = "base_logistic.stan",
  data = bayesian.base_reg.dat,
  iter = 1000
)
```

### Model with exclusion of highly correlated explanatory variables

why colllinearity is bad in Bayesian
The near-collinearity of the data means that the posterior variance of the regression coefficients would be high in this hypothetical case. Another problem in addition to increased uncertainty conditional on the regression model is that in practice the inferences would be highly sensitive to the modelâ€™s assumption that $E(y|x, \theta)$ is linear in x. (Bayesian Data Analysis, p. 366)

\begin{align}
  \beta_0 & \sim \text{Cauchy}(0, 10) \\
  \beta_1 & \sim \text{Cauchy}(0, 2.5) \\
  \beta_2 & \sim \text{Cauchy}(0, 2.5) \\
  \beta_5 & \sim \text{Cauchy}(0, 2.5) \\
  \beta_7 & \sim \text{Cauchy}(0, 2.5) \\
  \beta_9 & \sim \text{Cauchy}(0, 2.5) \\
  \beta_10 & \sim \text{Cauchy}(0, 2.5) \\
  y_n|\beta & \sim \text{Bern}(\text{logistic}(\beta_0 + \beta_1x_{n,1} + \beta_2x_{n,2} + \beta_5x_{n,5} + \beta_7x_{n,7} + \beta_9x_{n,9} + \beta_{10}x_{n,10})) & n \in \{1,...,n_\text{obs}\}
\end{align}

```{r, echo=FALSE}
bayesian.better_reg.dat <- list(
  N = 500,
  x1 = bayesian.train_data$radius1,
  x2 = bayesian.train_data$texture1,
  x5 = bayesian.train_data$smoothness1,
  x7 = bayesian.train_data$concavity1,
  x9 = bayesian.train_data$symmetry1,
  x10 = bayesian.train_data$fractal_dimension1,
  y = bayesian.train_data$Diagnosis,
  N_new = 69,
  x1_new = bayesian.test_data$radius1,
  x2_new = bayesian.test_data$texture1,
  x5_new = bayesian.test_data$smoothness1,
  x7_new = bayesian.test_data$concavity1,
  x9_new = bayesian.test_data$symmetry1,
  x10_new = bayesian.test_data$fractal_dimension1
)
```

```{r, message=FALSE}
bayesian.better_reg <- stan(
  seed = 123,
  file = "better_logistic.stan",
  data = bayesian.better_reg.dat,
  iter = 1000
)
```

### Model comparison

```{r}
waic(extract_log_lik(bayesian.base_reg))$waic
```

```{r}
waic(extract_log_lik(bayesian.better_reg))$waic
```

```{r}
loo(extract_log_lik(bayesian.base_reg))$looic
```

```{r}
loo(extract_log_lik(bayesian.better_reg))$looic
```

## Comparison between models from Frequentist and Bayesian approaches

Confidence vs Credible

## Appendix

```{r}
summary(frequentist.naive_reg)
```

```{r}
summary(frequentist.better_reg)
```

